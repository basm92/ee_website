---
title: "Solutions Tutorial 4"
format: html
---

## Estimating a FE Model

## Estimating a FD Model


## Visualizing Unobserved Heterogeneity

The "fixed effects" ($\alpha_i$) estimated in an FE model represent the time-invariant, unobserved characteristics of each individual (e.g., innate ability, motivation, family background) that affect their wage. Visualizing the distribution of these effects can reveal the extent of this heterogeneity.

1.  Estimate a Fixed Effects model for `lwage` using `exper`, `expersq`, and `union` as predictors.
2.  Extract the individual fixed effects from your estimated model.
3.  Create a **histogram or density plot** to visualize the distribution of these fixed effects.
4.  **Interpret the plot:** What does the shape and spread of the distribution tell you about the sample? Does it appear that unobserved, time-constant individual differences are a significant factor in explaining wage variation?

The histogram shows a wide spread of fixed effects, suggesting substantial unobserved time-constant heterogeneity across individuals. Since these effects capture persistent individual differences not explained by the predictors, their significant variation implies that individual-specific factors play an important role in wage determination. The roughly bell-shaped but somewhat skewed distribution indicates most individuals cluster around the mean effect, with some outliers showing particularly high or low baseline wages.

:::{.panel-tabset}

### Python

```{python}
#| echo: true
import pandas as pd
import pyfixest as pf
import matplotlib.pyplot as plt

# Load data
df = pd.read_stata("../tutorials/datafiles/WAGEPAN.DTA")

# Estimate FE model
fit = pf.feols("lwage ~ exper + expersq + union | nr", data=df)

# Extract fixed effects
fe = pd.DataFrame(fit.fixef())

# Plot distribution
plt.hist(fe, bins=30, density=True, alpha=0.7)
plt.xlabel("Individual Fixed Effects")
plt.title("Distribution of Fixed Effects")
plt.show()
```

### R

```{r}
#| echo: true
library(fixest); library(ggplot2); library(haven)

# Load data (adjust path as needed)
df <- haven::read_dta("../tutorials/datafiles/WAGEPAN.DTA")

# Estimate FE model
fit <- feols(lwage ~ exper + expersq + union | nr, data = df)

# Extract fixed effects
fe <- fixef(fit)$nr

# Plot distribution
ggplot(data.frame(fe), aes(x = fe)) +
  geom_histogram(aes(y = after_stat(density)), bins = 30, alpha = 0.7) +
  labs(x = "Individual Fixed Effects", 
       title = "Distribution of Fixed Effects") +
  theme_minimal()

```

### Stata

```{stata}
#| eval: false
#| echo: true
* Load data (adjust path as needed)
use "../tutorials/datafiles/WAGEPAN.DTA", clear

* Estimate FE model
xtset nr
xtreg lwage exper expersq union, fe

* Store fixed effects
predict fe, u

* Plot distribution
histogram fe, bin(30) frequency normal ///
    title("Distribution of Fixed Effects") ///
    xtitle("Individual Fixed Effects")
```

:::

## Efficiency of FD vs FE Estimators

- The FD error:
  
  The FD estimator works by differencing the equation to eliminate the fixed effect $c_i$:
  
  $\Delta y_{it} = \beta \Delta x_{it} + \Delta \epsilon_{it}$
  
  where $\Delta y_{it} = y_{it} - y_{i,t-1}$ and so on.
  
  Let's focus on the transformed error term, $\Delta \epsilon_{it}$:
  
  $\Delta \epsilon_{it} = \epsilon_{it} - \epsilon_{i,t-1}$
  
  Now, we substitute the definition of the random walk process for $\epsilon_{it}$:
  
  $\Delta \epsilon_{it} = (\epsilon_{i,t-1} + \nu_{it}) - \epsilon_{i,t-1}$
  
  This simplifies to:
  
  $\Delta \epsilon_{it} = \nu_{it}$
  
  Since $\nu_{it}$ is defined as white noise, it is, by definition, **not serially correlated**. Therefore, the error term in the first-differenced model satisfies the classical OLS assumption of no serial correlation.

- The FE error:
  
  Let's analyze the transformed error term, $\tilde{\epsilon}_{it} = \epsilon_{it} - \bar{\epsilon}_i$, where $\bar{\epsilon}_i = \frac{1}{T} \sum_{s=1}^{T} \epsilon_{is}$.
  
  The de-meaned error at time $t$ is:
  $\tilde{\epsilon}_{it} = \epsilon_{it} - \frac{1}{T}(\epsilon_{i1} + \epsilon_{i2} + ... + \epsilon_{iT})$
  
  And the de-meaned error at time $t-1$ is:
  $\tilde{\epsilon}_{i,t-1} = \epsilon_{i,t-1} - \frac{1}{T}(\epsilon_{i1} + \epsilon_{i2} + ... + \epsilon_{iT})$
  
  To check for serial correlation, we need to determine if the covariance between $\tilde{\epsilon}_{it}$ and $\tilde{\epsilon}_{i,t-1}$ is zero.
  
  $Cov(\tilde{\epsilon}_{it}, \tilde{\epsilon}_{i,t-1}) = E[(\epsilon_{it} - \bar{\epsilon}_i)(\epsilon_{i,t-1} - \bar{\epsilon}_i)]$
  
  Because $\epsilon_{it}$ is a random walk, it is strongly serially correlated with its own past values. For instance, $\epsilon_{it} = \epsilon_{i,t-1} + \nu_{it}$, and $\epsilon_{i,t-1} = \epsilon_{i,t-2} + \nu_{i,t-1}$, and so on. This means that $\epsilon_{it}$ is a sum of all past white noise shocks.
  
  When we de-mean this series, the transformed error $\tilde{\epsilon}_{it}$ becomes a complex combination of all the original error terms for that individual. Both $\tilde{\epsilon}_{it}$ and $\tilde{\epsilon}_{i,t-1}$ share the same subtracted mean, $\bar{\epsilon}_i$, and their non-mean components, $\epsilon_{it}$ and $\epsilon_{i,t-1}$, are themselves highly correlated. The de-meaning process does not remove the underlying correlation structure of a random walk.
  
  As a result, the covariance between the de-meaned errors, $Cov(\tilde{\epsilon}_{it}, \tilde{\epsilon}_{i,t-1})$, will be non-zero. The transformed error term in the FE model **remains serially correlated**.
  
