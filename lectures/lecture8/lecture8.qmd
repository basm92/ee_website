---
title: "Empirical Economics"
subtitle: "Lecture 8: Hands-on Econometrics"
mainfont: Lato
monofont: Ubuntu Mono
format:
  revealjs: 
    slide-number: true
    chalkboard: 
      buttons: false
    preview-links: auto
    logo: logo.svg
    css: styles.css
    footer: 'Empirical Economics: Lecture 8- Hands-on Econometrics'
resources:
  - demo.pdf
---

```{r setup}
#| warning: false
#| message: false
#| echo: false

library(ggplot2)
library(gridExtra)
library(reticulate)
use_python("/home/bas/anaconda3/bin/python")
```

# Introduction

## Course Overview

- Statistics and Probability - Basic Concepts
- Statistics and Probability - Hypothesis Testing
- The Linear Regression Model
- Time Series Data
- Panel Data (FE) and Control Variables
- Binary Outcome Data
- Potential Outcomes and Difference-in-differences
- Hands-on Econometrics in Practice

## Agenda 

- Data Wrangling and Cleaning
  - Importing Data
  - Merging Datasets
  - Pivoting
  - String Matching and subset search
- Data Cleaning
- Summary Tables
- Regression Tables
  - Standard Errors and Fit Statistics
- Visualization
- Project Organization

# Motivation

## Motivation

# Data Wrangling & Cleaning

## Importing Data

- Most of the data you'll receive is in a structured format

- Pay attention to _delimiters_, if you parse something like this:

- It isn't because the data is corrupted. It's just because the function you have used doesn't recognize the data format

## Merging Datasets

## Long and Wide Datasets

- Statistical packages usually assume your data is in a particular format, known as the _long format_:

```{python}
#| echo: false
import pandas as pd

# Create a sample long-format dataset
data_long = {
    'Company': ['Company A', 'Company A', 'Company B', 'Company B', 'Company C', 'Company C'],
    'Year': [2023, 2024, 2023, 2024, 2023, 2024],
    'Revenue': [100, 110, 200, 210, 150, 160],
    'Expenses': [80, 85, 150, 155, 120, 125]
}
df_long = pd.DataFrame(data_long)
print(df_long)
```

- Long Format:
  - In a long format, each row represents a single observation for a specific variable. For instance, in a firm-year dataset, you might have separate rows for the revenue of Company A in 2023 and the revenue of the same company in 2024. This format is often easier for data collection and storage.

- Wide Format: 
  - In a wide format, each row represents a single subject (like a company), and the columns represent different variables or observations over time. For example, you would have a single row for Company A with separate columns for "Revenue 2023" and "Revenue 2024". 

## Pivoting Datasets

- It often occurs that your data is in a slightly different format. Most often, your data is in a _wide format_:

```{python}
#| echo: false
# Pivot from long to wide format
df_wide = df_long.pivot(index='Company', columns='Year', values=['Revenue', 'Expenses'])
df_wide.columns = ['_'.join(map(str, col)) for col in df_wide.columns]
df_wide.reset_index(inplace=True)
print(df_wide)
```

## Pivoting Wider and Longer

- Fortunately, it's possible to _reshape_ `DataFrames` so as to switch between these formats at your convenience. 

- From Wide to Long:

:::{.panel-tabset .hey}
### R

```{r}
#| echo: true
#| code-fold: true
#| collapse: true
library(tidyverse, quietly=TRUE)
print(py$df_wide)
long_condensed <- py$df_wide |>
  pivot_longer(cols = contains(c('2023', '2024')), 
               names_to = 'variable',
               values_to = 'value')

print(long_condensed)
long_final <- long_condensed |>
  separate_wider_delim(variable, delim="_", names=c('variable', 'year'))

print(long_final)
```

### Python

```{python}
#| echo: true
#| code-fold: true
#| collapse: true

df_melted = pd.melt(df_wide, id_vars=['Company'], var_name='Metric_Year', value_name='Value')
print(df_melted)
# Split the 'Metric_Year' column into 'Metric' and 'Year'
df_melted[['Metric', 'Year']] = df_melted['Metric_Year'].str.split('_', expand=True)
df_melted.drop(columns='Metric_Year', inplace=True)
print(df_melted)
```

### Stata

:::

- From Long to Wide:

:::{.panel-tabset .hey}

### R 

```{r}
#| echo: true
#| collapse: true
#| code-fold: true

py$df_long |>
  pivot_wider(names_from="Year",
              values_from=c("Revenue", "Expenses"))

```

### Python  

```{python}
#| echo: true
#| code-fold: true
#| collapse: true
df_wide = df_long.pivot(index='Company', columns='Year', values=['Revenue', 'Expenses'])
print(df_wide)
df_wide.columns = ['_'.join(map(str, col)) for col in df_wide.columns]
df_wide.reset_index(inplace=True)
print(df_wide)

```

### Stata


:::

# Regression Tables

## Standard format

- After the introduction, the regression tables are probably the most important thing in your thesis. If you take away only one thing from this lecture, you must know that:

::::{.columns}

:::{.column width="50%"}
- Regression tables should always be formulated like this:

```{r}
#| echo: false
library(modelsummary); library(fixest); library(tinytable)
model <- feols(mpg ~ drat, data=mtcars)
model2 <- feols(mpg ~ drat + hp, data = mtcars)
model3 <- feols(mpg ~ drat + hp, vcov='hc1', data=mtcars)

modelsummary(list(model, model2, model3), gof_map=c("nobs", "r.squared"), output = 'tinytable') |>
  theme_tt("resize", width=1)
```

:::

:::{.column width="50%"}
- And they should never be raw output like this:

:::{style="font-size: 0.7em;"}
```{r}
#| echo: false
summary(model)
```
:::

:::

::::



## Regression Tables

- Regression tables will probably be some of the most important stuff in your thesis.

- They often form your central evidence, confirming or rejecting your hypothesis, answering your research question. 

- Anyone who reads your thesis farther than the introduction will probably look at them. 

- This is why **regression tables have to be formatted nicely**. 

- Fortunately, R/Python/Stata all have nice libraries allowing you to generate regression tables. 

- Hence, **you should never manually create a regression table, ever**. 

## Regression Tables (Cont.)

- Regression tables should have notes briefly describing what the regressions do. It should detail which method is used, how/which standard errors are computed and, traditionally, statistical significance. 

- They should also have an informative title. 
- Variable names should be properly and informatively formatted
  - In human-readable text, so "GDP per capita", not `gdp_per_capita`. 
  
## Regression Tables in R/Python/Stata

- Here are three full-fledged examples of nicely formatted regression tables. We'll go through all of the characteristics and their implementation.

:::{.panel-tabset}

### R

### Python

### Stata

:::

  
# Visualization

## What should we not show?

- Don't show, or incorporate into your thesis, any raw plotted figure you used to inspect your data
- I.e. a scatterplot like this is a no-go: 

```{r}
#| echo: false
#| fig-align: 'center'
#| fig-width: 8
mtcars |>
  ggplot(aes(x = drat, y = mpg)) + geom_point()
```

## What should we show?

- Always add a **title** and **clear labels** to your plot.
  - Make sure they're large enough.
- If you're unsure, ask somebody else to look at your plot.
  - If they don't get it, you probably created a bad plot.
- Pay attention to ticks and intercepts.
  
```{r}
#| echo: false
#| fig-align: 'center'
#| fig-width: 8

mtcars |>
  ggplot(aes(x=drat, y=mpg)) + geom_point() + 
  xlab("Rear axle ratio (drat)") +
  ylab("Miles/(US) Gallon (mpg)") + 
  ggtitle("Relationship between Rear axle ratio and Miles per gallon") +
  theme_bw()
```

## Use colors strategically

Here is some code that helps you set-up some basic acceptable scatter plots. 


## In what format should you save your graphics?

- Vector graphics are composed of formulas or paths.
  - "Draw a straight line from (0, 0) to (13, 4)."
  - Infinitely zoom-able. Preserves all underlying information.
  - May be slow to load when complex.
  - Extensions .pdf or .svg.

- Raster graphics are composed of pixels (a grid of squares with color information).
  - Only an approximation to the underlying shapes or points.
  - Work better with Microsoft Office and HTML.
  - Usually best: .png. Also .jpeg, .gif.

# Project Organization

## General principes

- A Master's thesis is likely the largest, most complex independent project you've ever managed.

-  The difference between a smooth, relatively low-stress process and a chaotic, last-minute scramble often comes down to the organization you set up at the very beginning.

- Adhering to these principles will make your thesis (hopefully) much less painful

## File Organization

- Create ONE main folder for your entire thesis.
- Use a numbered prefix system to keep folders in a logical, non-alphabetical order.

```
\master_thesis\
      \1_code\
        \1_download_data.py
        \2_bring_different_sources.py
        \3_rename_and_reshape_data.py
      \2_data\
        \1_stockprice.csv
        \2_accounting_info.json
        \intermediate_data\
          \stockprices_winsorized.csv
      \3_figures\
        \event_study.pdf
        \scatterplot.pdf
      \4_tables\
        \descriptive_statistics.tex
        \ols_baseline.tex
        \ols_robust_se.tex
        \autoregressive_1.tex
      \5_document\
        \thesis.docx
```

## File Organization (Cont.)

- Why numbers? Because it forces the folders into an order that *you* decide is logical, not the alphabet. 'Admin' won't end up at the top, and 'Writing' won't be at the bottom. 

- Keep your raw data in a separate folder and never touch itâ€”always work on a copy. Make a backup of this folder. Set up a cloud sync service today. 
  - You can use things like [Google Drive](http://drive.google.com), but also [DropBox](www.dropbox.com) and other commercial providers are available.
  
- Seperate files into inputs and outputs. 

- Don't use file names or directory names with spaces. 
  - Computer languages don't handle spaces well

## Organizing Literature

- Manual citation is a recipe for disaster. 
- Pick a tool **now** and use it for every paper you read.
  - Popular choices are Zotero, EndNote and Mendeley
  - You can also use [Overleaf](www.overleaf.com) if you're familiar with LaTeX

- Every time you download a paper, add it to your reference manager immediately. 

- When you're writing, you can insert citations directly from the manager.

## Code Organization

- Break programs into short scripts or functions, each of which conducts a single task.

- Make names distinctive and meaningful.

- Be consistent with code style and formatting.
  - Pay attention to things like file naming conventions and variable naming conventions

- Use relative filepaths ("../input/data.csv" instead of "C:/build/input/data.csv").
  - In VSCode, the working directory is always the **folder you have opened**. See [here](https://stackoverflow.com/questions/38623138/how-to-set-the-working-directory-for-debugging-a-python-program-in-vs-code) if you want to change that.
  - In RStudio, if you set up an [Rproj](https://support.posit.co/hc/en-us/articles/200526207-Using-RStudio-Projects), your working directory will also be the directory in which the `.Rproj` file is situated. 
  - In Stata, you can use `cd` to change your working directory. 
  
- Make incremental changes in your code, and test them as you go.


## Code Organization (Cont.)


- Save new copies of your scripts:
  - Every time you make a substantial revision.
  - If you make any edits to a script you haven't touched in more than 1-2 weeks.

- Comment often to explain the purpose of your code
  - Use descriptive variable names, e.g. `income_percapita` rather than `income_pc` or `inc_pc`

- Don't use spaces when naming variables. 
  - R: The `janitor` package has a function called `clean_names()`, which automatically converts column names into something compatible with R

- In Python, you could use something like this:

:::{style="font-size: 0.7em;"}
```{python}
#| echo: true
#| code-fold: true
#| eval: false
import re

def clean_col_names(col_name):
    """A more robust function to clean column names."""
    # Convert to lowercase
    new_col = col_name.lower()
    # Replace any non-alphanumeric characters with an underscore
    new_col = re.sub(r'[^A-Za-z0-9]+', '_', new_col)
    # Remove leading/trailing underscores
    new_col = new_col.strip('_')
    return new_col

# Apply the function to all columns
df.columns = [clean_col_names(col) for col in df_messy_copy.columns]
```
:::


## Version Control

- We've all been guilty of the 'Final_Final' file name. 
  - This creates confusion and risk. 
  - A simple, robust naming convention using dates in the `YEAR-MONTH-DAY` format is a great start because it sorts chronologically.
  
- If you're working a lot with code or LaTeX, I strongly encourage you to look into Git.
  - It's the professional standard for a reason. 
  - For Word documents, leverage the version history that's built into tools like Google Docs or OneDrive.


# Summary

## What did we do?

## Other Resources

- [This](https://github.com/uo-ec607/lectures)
- [This](https://github.com/msu-econ-data-analytics/course-materials?tab=readme-ov-file)


