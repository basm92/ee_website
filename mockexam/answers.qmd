---
title: "Answers Mock Midterm"
format: pdf
---

# Answer Key

## Multiple Choice Questions

1.  **b)** The goal is to forecast a value ($\hat{y}$) as accurately as possible, which is the definition of a prediction task.

2.  **d)** The data tracks the same cross-sectional units (individuals) over multiple time periods, which defines panel data.

3.  **c)** One of the OLS First Order Conditions directly implies that the sum of the explanatory variable multiplied by the residual is zero ($\sum x_i \hat{u}_i = 0$), which means their sample covariance is zero.

4.  **b)** In a log-log model, the slope coefficient is an elasticity, representing the percentage change in the dependent variable for a 1% change in the independent variable.

5.  **b)** For males, the dummy variable `Female` is 0. Therefore, the predicted wage is $\widehat{\text{Wage}} = 22.50 - 3.75 \times (0) = 22.50$. The intercept represents the average value for the reference group.

6.  **c)** R-squared measures the proportion of the sample variation in the dependent variable that is explained by the independent variable(s).

7.  **c)** The omitted variable ("parental involvement") has a positive effect on test scores ($\beta_2 > 0$). It is negatively correlated with the included variable, ClassSize ($\delta_1 < 0$). The bias is the product of these two effects: $(\text{positive}) \times (\text{negative}) = \text{negative bias}$. This negative bias will make the estimated coefficient for class size more negative (i.e., appear larger in magnitude) than the true effect.

8.  **d)** The formula for the variance is $\widehat{Var}(\hat{\beta}_1) = \frac{\hat{\sigma}^2}{SST_x}$. To decrease the variance, one must either decrease the numerator (error variance) or increase the denominator. Increasing the variation in the explanatory variable ($SST_x$) increases the denominator, thus decreasing the overall variance.

9. **c)** The student must start with the formula relating the estimated coefficient to the true coefficient and the bias:

$E[\hat{\alpha}_1] = \beta_1 + \text{Bias}$

Then, use the specific formula for omitted variable bias:
$\text{Bias} = \beta_2 \cdot \delta_1$

From the problem description:

*   The true effect of the included variable is $\beta_1 = 2.5$.
*   The true effect of the omitted variable is $\beta_2 = 4.0$.
*   The coefficient from the auxiliary regression of the omitted variable on the included variable is $\delta_1 = 0.5$.

First, calculate the bias:
$\text{Bias} = 4.0 \times 0.5 = 2.0$

Next, use this to find the expected value of the estimated coefficient:
$E[\hat{\alpha}_1] = 2.5 + 2.0 = 4.5$

10. **c)** Use the formula of the estimated model to derive the expected wage for each category and then find the difference.

**Expected wage for a Finance worker:** For this person, `Finance` = 1 and `Retail` = 0.
    $E[\text{Wage} | \text{Finance}] = 18.50 - 2.10 \times (0) + 5.40 \times (1) = 18.50 + 5.40 = 23.90$

**Expected wage for a Retail worker:** For this person, `Retail` = 1 and `Finance` = 0.
    $E[\text{Wage} | \text{Retail}] = 18.50 - 2.10 \times (1) + 5.40 \times (0) = 18.50 - 2.10 = 16.40$

**Calculate the difference:**
    Difference = $E[\text{Wage} | \text{Finance}] - E[\text{Wage} | \text{Retail}]$
    Difference = $23.90 - 16.40 = 7.50$

*Alternative algebraic derivation:*
Let $\hat{\beta}_0 = 18.50$, $\hat{\beta}_1 = -2.10$, and $\hat{\beta}_2 = 5.40$.
The difference is $(\hat{\beta}_0 + \hat{\beta}_2) - (\hat{\beta}_0 + \hat{\beta}_1) = \hat{\beta}_2 - \hat{\beta}_1 = 5.40 - (-2.10) = 5.40 + 2.10 = 7.50$.

11.  **c)** The effect of a one-unit change in $x_1$ on $y$, holding $x_2$ constant.

12.  **c)** A confounder, and failing to control for it will likely lead to omitted variable bias.

13.  **b)** An F-test for the overall significance of the regression.

14.  **c)** The standard errors for the coefficients $\hat{\beta}_1$ and $\hat{\beta}_2$ will be large.

15.  **d)** The difference in the return to an additional year of education for females compared to males.

16.  **c)** The lecture explicitly states that if $|\rho|=1$, the series is non-stationary and is called a random walk, where shocks have a permanent effect.

17.  **b)** The Long-Run Multiplier is defined as the total effect on Y after a permanent change in X has fully worked through the system, and it is calculated as the ratio of the sum of the distributed lag coefficients to one minus the sum of the autoregressive coefficients.

18. **c)** For an MA(q) model, any forecast for a horizon h > q will only involve future error terms, whose conditional expectation is zero. Therefore, the forecast reverts to the process mean: $\hat{Y}_{t+h|t} = \mu$.

19. **c)** The "Within" estimator works by performing a "within transformation" or "de-meaning." For each individual, it calculates the average of the dependent and independent variables over time and subtracts these individual-specific averages from the original data. This process removes the time-constant individual effect ($a_i$), as $\alpha_i - \bar{\alpha}_i = 0$.

20. **c)** The Fixed Effects model eliminates all variables that are constant over time for an individual. Since the firm's industry sector does not change, it would be absorbed into the individual-specific fixed effect ($a_i$) and its coefficient cannot be estimated. The other variables (innovation, age, unemployment rate) all vary over time.

## Open Questions

## Question 1

## Question 2

## Question 3

## Question 4

**Part a)**

*   **One-Step-Ahead Forecast (for 2025, Q1):**
    *   First, recognize that $t-1$ corresponds to $2024, \text{ Q4}$ and $t-2$ corresponds to $2024, \text{ Q3}$.
    *   Calculation:
        $\text{Forecast}(\text{Q1}) = 0.2 + 1.2 \times (\text{INFLATION}_{2024, \text{ Q4}}) - 0.4 \times (\text{INFLATION}_{2024, \text{ Q3}})$
        
        $\text{Forecast}(\text{Q1}) = 0.2 + 1.2 \times (3.0) - 0.4 \times (2.5)$
        
        $\text{Forecast}(\text{Q1}) = 0.2 + 3.6 - 1.0 = 2.8$
        
    *   The forecast for 2025 Q1 is **2.8%**.

*   **Two-Step-Ahead Forecast (for 2025, Q2):**
    *   Crucially, use the **forecasted value** for $t-1$ and the known actual value for $t-2$.
    *   Calculation:
        $\text{Forecast}(\text{Q2}) = 0.2 + 1.2 \times (\text{Forecast}(\text{Q1})) - 0.4 \times (\text{INFLATION}_{2024, \text{ Q4}})$
        
        $\text{Forecast}(\text{Q2}) = 0.2 + 1.2 \times (2.8) - 0.4 \times (3.0)$
        
        $\text{Forecast}(\text{Q2}) = 0.2 + 3.36 - 1.2 = 2.36$
        
    *   The forecast for 2025 Q2 is **2.36%**.

**Part b)**

*   **Forecast Errors:** Calculate the difference $e_t = Y_t - \hat{Y}_t$.
    *   Error for Q1: $e_1 = 3.5\% (\text{Actual}) - 2.8\% (\text{Forecast}) = 0.7$
    *   Error for Q2: $e_2 = 3.8\% (\text{Actual}) - 2.36\% (\text{Forecast}) = 1.44$

*   **Root Mean Squared Error (RMSE) Calculation:**
    *   First, calculate the Mean Squared Error (MSE):
        $\text{MSE} = \frac{e_1^2 + e_2^2}{2} = \frac{0.7^2 + 1.44^2}{2}$
        $\text{MSE} = \frac{0.49 + 2.0736}{2} = \frac{2.5636}{2} = 1.2818$
    *   Then, take the square root to get the RMSE:
        $\text{RMSE} = \sqrt{1.2818} \approx 1.132$

*   **Interpretation:** The RMSE is approximately **1.13**. The student should explain that this value means that, on average, the model's forecasts for inflation over this two-quarter period were off by about **1.13 percentage points**. Since the RMSE is in the same units as the original variable, it provides a direct and interpretable measure of the typical size of a forecast error.


## Question 5

This answer model is very extensive, you don't have to be as extensive in your answer.

**Part a)** Let the true relationship between productivity and training be represented by the following linear model:

$$
\text{Productivity}_{it} = \beta_0 + \beta_1 \text{Training}_{it} + a_i + u_{it}
$$

Here, $i$ indexes the employee and $t$ indexes the time period. The term $a_i$ represents the **unobserved heterogeneity**, such as an employee's innate ability or motivation. It is specific to each individual but constant over time. The term $u_{it}$ is the idiosyncratic error.

The statistical problem of omitted variable bias arises if this unobserved effect $a_i$ is correlated with an included explanatory variable. In this context, two conditions are likely to hold:

1.  **Correlation with the regressor:** Employees with higher innate ability ($a_i$) may be more likely to receive or seek out training. $\text{Cov}(\text{Training}_{it}, a_i) \neq 0$

2.  **Correlation with the outcome:** Innate ability ($a_i$) directly affects an employee's output. $\text{Cov}(\text{Productivity}_{it}, a_i) \neq 0$

If a simple OLS regression is performed, the model being estimated is $\text{Productivity}_{it} = \beta_0 + \beta_1 \text{Training}_{it} + v_{it}$, where the error term $v_{it} = a_i + u_{it}$ now contains the unobserved heterogeneity. For the OLS estimator of $\beta_1$ to be unbiased and consistent, the explanatory variable must be uncorrelated with the error term, requiring $\text{Cov}(\text{Training}_{it}, v_{it}) = 0$.

However, due to the correlation between training and ability, this condition is violated:

$$
\text{Cov}(\text{Training}_{it}, v_{it}) = \text{Cov}(\text{Training}_{it}, a_i + u_{it}) = \text{Cov}(\text{Training}_{it}, a_i)
$$

(assuming $\text{Cov}(\text{Training}_{it}, u_{it})=0$).

Since $\text{Cov}(\text{Training}_{it}, a_i) \neq 0$, the OLS assumption is violated. The resulting estimator for $\beta_1$ will be biased, capturing not only the effect of training but also spuriously attributing the effect of innate ability to the training variable.

**Part b)** The Fixed Effects (FE) estimator mechanically eliminates the time-invariant unobserved heterogeneity $a_i$ from the model by applying the **"within transformation."** This process consists of two steps:

**Step 1: Calculate the time-average for each individual.** For each employee $i$, we average the original equation over all $T$ time periods:

$$
\frac{1}{T} \sum_{t=1}^{T} \text{Productivity}_{it} = \frac{1}{T} \sum_{t=1}^{T} (\beta_0 + \beta_1 \text{Training}_{it} + a_i + u_{it})
$$

Using the notation $\bar{x}_i = \frac{1}{T} \sum_{t=1}^{T} x_{it}$ for the time-average, this becomes:

$$
\overline{\text{Productivity}}_i = \beta_0 + \beta_1 \overline{\text{Training}}_i + \bar{a}_i + \bar{u}_i
$$

Because $a_i$ is constant over time for each individual, its average is simply itself: $\bar{a}_i = a_i$. The averaged equation is therefore:

$$
\overline{\text{Productivity}}_i = \beta_0 + \beta_1 \overline{\text{Training}}_i + a_i + \bar{u}_i
$$

**Step 2: Subtract the time-averaged equation from the original equation (de-meaning).** Subtracting the averaged equation (for individual $i$) from the original equation (for individual $i$ at time $t$) yields:

$$
(\text{Productivity}_{it} - \overline{\text{Productivity}}_i) = \beta_1(\text{Training}_{it} - \overline{\text{Training}}_i) + (a_i - a_i) + (u_{it} - \bar{u}_i)
$$

The unobserved effect $a_i$ is perfectly eliminated from the equation. Using the "de-meaned" or "within" notation where $\ddot{x}_{it} = x_{it} - \bar{x}_i$, the transformed model is:

$$
\ddot{\text{Productivity}}_{it} = \beta_1 \ddot{\text{Training}}_{it} + \ddot{u}_{it}
$$

By applying OLS to this transformed equation, we obtain the Fixed Effects estimator for $\beta_1$. This estimator is consistent because the source of the endogeneity, $a_i$, has been removed. The coefficient $\beta_1$ is now estimated using only the variation *within* each employee's productivity and training over time.


