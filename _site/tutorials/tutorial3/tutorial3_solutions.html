<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.54">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Solutions Tutorial 3 – Empirical Economics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../style.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Empirical Economics</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../lectureslides.html"> 
<span class="menu-text">Lecture Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../tutorialslides.html"> 
<span class="menu-text">Tutorial Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../tutorialanswers.html"> 
<span class="menu-text">Tutorial Answers</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../mockexams.html"> 
<span class="menu-text">Mock Exam</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#housing-prices" id="toc-housing-prices" class="nav-link active" data-scroll-target="#housing-prices">Housing prices</a></li>
  <li><a href="#log-log-model" id="toc-log-log-model" class="nav-link" data-scroll-target="#log-log-model">Log-Log Model</a></li>
  <li><a href="#error-term-and-residual" id="toc-error-term-and-residual" class="nav-link" data-scroll-target="#error-term-and-residual">Error Term and Residual</a></li>
  <li><a href="#proving-a-fundamental-ols-property" id="toc-proving-a-fundamental-ols-property" class="nav-link" data-scroll-target="#proving-a-fundamental-ols-property">Proving a Fundamental OLS Property</a></li>
  <li><a href="#unbiasedness" id="toc-unbiasedness" class="nav-link" data-scroll-target="#unbiasedness">Unbiasedness</a></li>
  <li><a href="#omitted-variable-bias" id="toc-omitted-variable-bias" class="nav-link" data-scroll-target="#omitted-variable-bias">Omitted Variable Bias</a></li>
  <li><a href="#marginal-effects" id="toc-marginal-effects" class="nav-link" data-scroll-target="#marginal-effects">Marginal Effects</a></li>
  <li><a href="#perfect-multicollinearity" id="toc-perfect-multicollinearity" class="nav-link" data-scroll-target="#perfect-multicollinearity">Perfect Multicollinearity</a></li>
  <li><a href="#zero-conditional-mean" id="toc-zero-conditional-mean" class="nav-link" data-scroll-target="#zero-conditional-mean">Zero Conditional Mean</a></li>
  <li><a href="#variance-of-the-ols-estimator" id="toc-variance-of-the-ols-estimator" class="nav-link" data-scroll-target="#variance-of-the-ols-estimator">Variance of the OLS Estimator</a></li>
  <li><a href="#r-squared" id="toc-r-squared" class="nav-link" data-scroll-target="#r-squared">R-squared</a></li>
  <li><a href="#omitted-variable-bias-1" id="toc-omitted-variable-bias-1" class="nav-link" data-scroll-target="#omitted-variable-bias-1">Omitted Variable Bias</a></li>
  <li><a href="#ols-minimization" id="toc-ols-minimization" class="nav-link" data-scroll-target="#ols-minimization">OLS Minimization</a></li>
  <li><a href="#polynomials" id="toc-polynomials" class="nav-link" data-scroll-target="#polynomials">Polynomials</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="tutorial3_solutions.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Solutions Tutorial 3</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="housing-prices" class="level3">
<h3 class="anchored" data-anchor-id="housing-prices">Housing prices</h3>
<p>The regression model is: <code>price = 300,000 + 1500 * sqmtr</code>, with R² = 0.64.</p>
<p><strong>(a) Interpret the intercept (300,000) and the slope coefficient (1,500) in plain English.</strong></p>
<ul>
<li><p><strong>Intercept (300,000):</strong> This is the predicted price of a house with 0 square meters of interior surface. In this context, the intercept has no meaningful practical interpretation, as a house cannot have zero square meters. It is a statistical construct that helps position the regression line correctly in the data cloud.</p></li>
<li><p><strong>Slope (1,500):</strong> For each additional square meter of interior surface, the sale price of a house is predicted to increase by 1,500 euros, holding all other factors constant.</p></li>
</ul>
<p><strong>(b) What does the R-squared value of 0.64 tell us about this model?</strong></p>
<ul>
<li>An R-squared of 0.64 means that <strong>64% of the total variation in house prices (<code>price</code>) is explained by the variation in the interior surface (<code>sqmtr</code>)</strong>. The remaining 36% of the variation in price is due to other factors not included in the model (e.g., location, age of the house, number of bedrooms, etc.).</li>
</ul>
<p><strong>(c) If you were to re-estimate the model with price measured in thousands of euros (e.g., a 250,000 euro house becomes 250), what would the new equation be?</strong></p>
<ul>
<li>If we divide the dependent variable <code>price</code> by 1,000, we must also divide the entire right-hand side of the equation by 1,000 to maintain the equality. Let <code>price_k</code> be the price in thousands of euros. <span class="math display">\[
\frac{\text{price}}{1000} = \frac{300,000}{1000} + \frac{1500}{1000} \times \text{sqmtr}
\]</span></li>
<li>The new equation would be: <code>price_k = 300 + 1.5 * sqmtr</code></li>
<li>The interpretation changes accordingly: The intercept is now 300 thousand euros, and each additional square meter increases the predicted price by 1.5 measured in the new units (thousands of euros).</li>
</ul>
</section>
<section id="log-log-model" class="level3">
<h3 class="anchored" data-anchor-id="log-log-model">Log-Log Model</h3>
<p>The regression result is: <code>log(Sales) = 2.1 - 0.85 * log(Ad_Price)</code>.</p>
<p><strong>How would you interpret the coefficient -0.85? What is the economic term for this value?</strong></p>
<ul>
<li><strong>Interpretation:</strong> In a log-log model, the coefficient represents an elasticity. A <strong>1% increase in the advertising price (<code>Ad_Price</code>) is associated with a 0.85% decrease in product sales (<code>Sales</code>)</strong>, on average.</li>
<li><strong>Economic Term:</strong> This value is the <strong>price elasticity of demand</strong>. Since the absolute value is less than 1 (|-0.85| &lt; 1), we would say that the demand for the product is <strong>inelastic</strong> with respect to the advertising price.</li>
</ul>
</section>
<section id="error-term-and-residual" class="level3">
<h3 class="anchored" data-anchor-id="error-term-and-residual">Error Term and Residual</h3>
<p><strong>What is the fundamental difference between the population error term (<span class="math inline">\(u_i\)</span>) and the OLS residual (<span class="math inline">\(e_i\)</span>)? Why can we observe one but not the other?</strong></p>
<ul>
<li><strong>Fundamental Difference:</strong>
<ul>
<li>The <strong>population error term (<span class="math inline">\(u_i\)</span>)</strong> is the vertical distance between a data point (<span class="math inline">\(y_i\)</span>) and the <em>true, unobservable population regression line</em>. It represents all the unobserved factors that affect <span class="math inline">\(y_i\)</span> besides <span class="math inline">\(x_i\)</span>. <span class="math inline">\(u_i = y_i - (\beta_0 + \beta_1 x_i)\)</span></li>
<li>The <strong>OLS residual (<span class="math inline">\(e_i\)</span> or <span class="math inline">\(\hat{u}_i\)</span>)</strong> is the vertical distance between a data point (<span class="math inline">\(y_i\)</span>) and the <em>estimated sample regression line</em>. It is the prediction error from our estimated model. <span class="math inline">\(e_i = y_i - \hat{y}_i = y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i)\)</span></li>
</ul></li>
<li><strong>Why we can’t observe <span class="math inline">\(u_i\)</span>:</strong> We cannot observe the population error term <span class="math inline">\(u_i\)</span> because we do not know the true population parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. We can only estimate them using a sample of data, which gives us <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span>. Because we can calculate <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> from our sample, we can calculate the residual <span class="math inline">\(e_i\)</span> for each observation.</li>
</ul>
</section>
<section id="proving-a-fundamental-ols-property" class="level3">
<h3 class="anchored" data-anchor-id="proving-a-fundamental-ols-property">Proving a Fundamental OLS Property</h3>
<p><strong>Using the formula for the OLS intercept estimator, <span class="math inline">\(\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}\)</span>, prove that the regression line passes through the point of sample means, <span class="math inline">\((\bar{x}, \bar{y})\)</span>.</strong></p>
<ol type="1">
<li><p>The estimated OLS regression line is given by the equation: <span class="math inline">\(\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x\)</span></p></li>
<li><p>To show that the line passes through the point <span class="math inline">\((\bar{x}, \bar{y})\)</span>, we need to show that when we plug in <span class="math inline">\(x=\bar{x}\)</span>, the predicted value <span class="math inline">\(\hat{y}\)</span> is equal to <span class="math inline">\(\bar{y}\)</span>.</p></li>
<li><p>Substitute the formula for the intercept, <span class="math inline">\(\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}\)</span>, into the regression equation: <span class="math inline">\(\hat{y} = (\bar{y} - \hat{\beta}_1 \bar{x}) + \hat{\beta}_1 x\)</span></p></li>
<li><p>Now, set <span class="math inline">\(x = \bar{x}\)</span>: <span class="math inline">\(\hat{y} = (\bar{y} - \hat{\beta}_1 \bar{x}) + \hat{\beta}_1 \bar{x}\)</span></p></li>
<li><p>The terms <span class="math inline">\(-\hat{\beta}_1 \bar{x}\)</span> and <span class="math inline">\(+\hat{\beta}_1 \bar{x}\)</span> cancel each other out: <span class="math inline">\(\hat{y} = \bar{y}\)</span></p></li>
</ol>
<p>This proves that when the input is the sample mean of x, the predicted output is the sample mean of y. Therefore, the OLS regression line always passes through the point of sample means <span class="math inline">\((\bar{x}, \bar{y})\)</span>.</p>
</section>
<section id="unbiasedness" class="level3">
<h3 class="anchored" data-anchor-id="unbiasedness">Unbiasedness</h3>
<p><strong>(a) Show that the estimator can be rewritten as: <span class="math inline">\(\hat{\beta}_1 = \beta_1 + \frac{\sum_{i=1}^{n} (x_i - \bar{x})u_i}{\sum_{i=1}^{n} (x_i - \bar{x})^2}\)</span></strong></p>
<ol type="1">
<li><p>Start with the formula for <span class="math inline">\(\hat{\beta}_1\)</span>: <span class="math display">\[ \hat{\beta}_1 = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sum (x_i - \bar{x})^2} \]</span> A useful property is <span class="math inline">\(\sum (x_i - \bar{x})(y_i - \bar{y}) = \sum (x_i - \bar{x})y_i\)</span>. So, <span class="math display">\[ \hat{\beta}_1 = \frac{\sum (x_i - \bar{x})y_i}{\sum (x_i - \bar{x})^2} \]</span></p></li>
<li><p>Substitute the true population model <span class="math inline">\(y_i = \beta_0 + \beta_1 x_i + u_i\)</span> for <span class="math inline">\(y_i\)</span>: <span class="math display">\[ \hat{\beta}_1 = \frac{\sum (x_i - \bar{x})(\beta_0 + \beta_1 x_i + u_i)}{\sum (x_i - \bar{x})^2} \]</span></p></li>
<li><p>Distribute the term <span class="math inline">\((x_i - \bar{x})\)</span> in the numerator: <span class="math display">\[ \hat{\beta}_1 = \frac{\sum (x_i - \bar{x})\beta_0 + \sum (x_i - \bar{x})\beta_1 x_i + \sum (x_i - \bar{x})u_i}{\sum (x_i - \bar{x})^2} \]</span></p></li>
<li><p>Analyze each term in the numerator:</p>
<ul>
<li><span class="math inline">\(\sum (x_i - \bar{x})\beta_0 = \beta_0 \sum (x_i - \bar{x}) = \beta_0 \cdot 0 = 0\)</span>.</li>
<li><span class="math inline">\(\sum (x_i - \bar{x})\beta_1 x_i = \beta_1 \sum (x_i - \bar{x})x_i\)</span>. Using the same property as step 1, <span class="math inline">\(\sum (x_i - \bar{x})x_i = \sum (x_i - \bar{x})(x_i - \bar{x}) = \sum (x_i - \bar{x})^2\)</span>. So this term is <span class="math inline">\(\beta_1 \sum (x_i - \bar{x})^2\)</span>.</li>
<li><span class="math inline">\(\sum (x_i - \bar{x})u_i\)</span> remains as is.</li>
</ul></li>
<li><p>Substitute these back into the expression: <span class="math display">\[ \hat{\beta}_1 = \frac{0 + \beta_1 \sum (x_i - \bar{x})^2 + \sum (x_i - \bar{x})u_i}{\sum (x_i - \bar{x})^2} \]</span></p></li>
<li><p>Separate the fraction: <span class="math display">\[ \hat{\beta}_1 = \frac{\beta_1 \sum (x_i - \bar{x})^2}{\sum (x_i - \bar{x})^2} + \frac{\sum (x_i - \bar{x})u_i}{\sum (x_i - \bar{x})^2} \]</span></p></li>
<li><p>Simplify to get the final result: <span class="math display">\[ \hat{\beta}_1 = \beta_1 + \frac{\sum_{i=1}^{n} (x_i - \bar{x})u_i}{\sum_{i=1}^{n} (x_i - \bar{x})^2} \]</span></p></li>
</ol>
<p><strong>(b) Take the conditional expectation… to prove that <span class="math inline">\(E(\hat{\beta}_1|X) = \beta_1\)</span>.</strong></p>
<ol type="1">
<li><p>Start with the expression from part (a): <span class="math display">\[ \hat{\beta}_1 = \beta_1 + \frac{\sum (x_i - \bar{x})u_i}{\sum (x_i - \bar{x})^2} \]</span></p></li>
<li><p>Take the expectation of both sides, conditional on <span class="math inline">\(X = \{x_1, x_2, ..., x_n\}\)</span>: <span class="math display">\[ E(\hat{\beta}_1|X) = E\left(\beta_1 + \frac{\sum (x_i - \bar{x})u_i}{\sum (x_i - \bar{x})^2} \bigg| X\right) \]</span></p></li>
<li><p>Use the linearity of expectation: <span class="math display">\[ E(\hat{\beta}_1|X) = E(\beta_1|X) + E\left(\frac{\sum (x_i - \bar{x})u_i}{\sum (x_i - \bar{x})^2} \bigg| X\right) \]</span></p></li>
<li><p>Analyze each term:</p>
<ul>
<li><span class="math inline">\(E(\beta_1|X) = \beta_1\)</span> because <span class="math inline">\(\beta_1\)</span> is a constant.</li>
<li>For the second term, since we are conditioning on <span class="math inline">\(X\)</span>, all <span class="math inline">\(x_i\)</span> and <span class="math inline">\(\bar{x}\)</span> values are treated as non-random. We can pull them outside the expectation: <span class="math display">\[ E\left(\frac{\sum (x_i - \bar{x})u_i}{\sum (x_i - \bar{x})^2} \bigg| X\right) = \frac{1}{\sum (x_i - \bar{x})^2} E\left(\sum (x_i - \bar{x})u_i \bigg| X\right) \]</span> <span class="math display">\[ = \frac{1}{\sum (x_i - \bar{x})^2} \sum (x_i - \bar{x}) E(u_i | X) \]</span></li>
</ul></li>
<li><p>Now, use the <strong>Zero Conditional Mean assumption</strong>, <span class="math inline">\(E(u_i|X) = 0\)</span>. This means the entire second term becomes zero: <span class="math display">\[ \frac{1}{\sum (x_i - \bar{x})^2} \sum (x_i - \bar{x}) \cdot 0 = 0 \]</span></p></li>
<li><p>Substitute back into the main equation: <span class="math display">\[ E(\hat{\beta}_1|X) = \beta_1 + 0 \]</span> <span class="math display">\[ E(\hat{\beta}_1|X) = \beta_1 \]</span> This proves that the OLS slope estimator is unbiased.</p></li>
</ol>
</section>
<section id="omitted-variable-bias" class="level3">
<h3 class="anchored" data-anchor-id="omitted-variable-bias">Omitted Variable Bias</h3>
<p><strong>Show that the expected value of the estimator from the incorrect short regression is <span class="math inline">\(E(\hat{\gamma}_1) = \beta_1 + \beta_2 \cdot \delta_1\)</span>.</strong></p>
<ol type="1">
<li><p>The estimated coefficient from the incorrect (short) regression of <span class="math inline">\(y\)</span> on <span class="math inline">\(x_1\)</span> is: <span class="math display">\[ \hat{\gamma}_1 = \frac{\sum(x_{1i}-\bar{x}_1)y_i}{\sum(x_{1i}-\bar{x}_1)^2} \]</span></p></li>
<li><p>Substitute the <em>true</em> population model for <span class="math inline">\(y_i\)</span>: <span class="math inline">\(y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + u_i\)</span>. <span class="math display">\[ \hat{\gamma}_1 = \frac{\sum(x_{1i}-\bar{x}_1)(\beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + u_i)}{\sum(x_{1i}-\bar{x}_1)^2} \]</span></p></li>
<li><p>Distribute the numerator and separate the terms, just as in the unbiasedness proof: <span class="math display">\[ \hat{\gamma}_1 = \frac{\sum(x_{1i}-\bar{x}_1)\beta_0}{\sum(x_{1i}-\bar{x}_1)^2} + \frac{\sum(x_{1i}-\bar{x}_1)\beta_1 x_{1i}}{\sum(x_{1i}-\bar{x}_1)^2} + \frac{\sum(x_{1i}-\bar{x}_1)\beta_2 x_{2i}}{\sum(x_{1i}-\bar{x}_1)^2} + \frac{\sum(x_{1i}-\bar{x}_1)u_i}{\sum(x_{1i}-\bar{x}_1)^2} \]</span></p></li>
<li><p>Simplify each term:</p>
<ul>
<li>The first term is 0. (Covariance with a constant)</li>
<li>The second term simplifies to <span class="math inline">\(\beta_1\)</span>.</li>
<li>The third term can be rewritten as <span class="math inline">\(\beta_2 \left( \frac{\sum(x_{1i}-\bar{x}_1)x_{2i}}{\sum(x_{1i}-\bar{x}_1)^2} \right)\)</span>.</li>
<li>The fourth term remains. So, <span class="math display">\[ \hat{\gamma}_1 = \beta_1 + \beta_2 \left( \frac{\sum(x_{1i}-\bar{x}_1)(x_{2i}-\bar{x}_2)}{\sum(x_{1i}-\bar{x}_1)^2} \right) + \frac{\sum(x_{1i}-\bar{x}_1)u_i}{\sum(x_{1i}-\bar{x}_1)^2} \]</span> <em>(Note: We can replace <span class="math inline">\(x_{2i}\)</span> with <span class="math inline">\((x_{2i}-\bar{x}_2)\)</span> in the numerator because <span class="math inline">\(\sum(x_{1i}-\bar{x}_1)\bar{x}_2=0\)</span>.)</em></li>
</ul></li>
<li><p>Recognize that the term in the parenthesis is the formula for the OLS slope coefficient from a regression of <span class="math inline">\(x_2\)</span> on <span class="math inline">\(x_1\)</span>. Let’s call this <span class="math inline">\(\hat{\delta}_1\)</span>. <span class="math display">\[ \hat{\delta}_1 = \frac{\text{Cov}(x_1, x_2)}{\text{Var}(x_1)} = \frac{\sum(x_{1i}-\bar{x}_1)(x_{2i}-\bar{x}_2)}{\sum(x_{1i}-\bar{x}_1)^2} \]</span> The equation becomes: <span class="math inline">\(\hat{\gamma}_1 = \beta_1 + \beta_2 \hat{\delta}_1 + \text{error term involving u}\)</span>.</p></li>
<li><p>Now, take the expectation. We assume that in the population, the relationship between <span class="math inline">\(x_2\)</span> and <span class="math inline">\(x_1\)</span> is <span class="math inline">\(E(x_2|x_1) = \delta_0 + \delta_1 x_1\)</span>. So <span class="math inline">\(E(\hat{\delta}_1) = \delta_1\)</span>. <span class="math display">\[ E(\hat{\gamma}_1) = E(\beta_1) + E(\beta_2 \hat{\delta}_1) + E(\text{error term}) \]</span> <span class="math display">\[ E(\hat{\gamma}_1) = \beta_1 + \beta_2 E(\hat{\delta}_1) + 0 \quad (\text{since } E(u|X)=0) \]</span> <span class="math display">\[ E(\hat{\gamma}_1) = \beta_1 + \beta_2 \delta_1 \]</span> The term <span class="math inline">\(\beta_2 \delta_1\)</span> is the <strong>omitted variable bias</strong>.</p></li>
</ol>
</section>
<section id="marginal-effects" class="level3">
<h3 class="anchored" data-anchor-id="marginal-effects">Marginal Effects</h3>
<p><strong>(a) The Quadratic Model:</strong> For <span class="math inline">\(y = \beta_0 + \beta_1 x + \beta_2 x^2 + u\)</span>, find <span class="math inline">\(\frac{dy}{dx}\)</span>.</p>
<ul>
<li>To find the marginal effect of <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span>, we take the partial derivative of <span class="math inline">\(y\)</span> with respect to <span class="math inline">\(x\)</span>: <span class="math display">\[ \frac{\partial y}{\partial x} = \frac{\partial}{\partial x} (\beta_0 + \beta_1 x + \beta_2 x^2 + u) \]</span> <span class="math display">\[ \frac{\partial y}{\partial x} = 0 + \beta_1 + 2\beta_2 x + 0 \]</span> <span class="math display">\[ \frac{\partial y}{\partial x} = \beta_1 + 2\beta_2 x \]</span></li>
<li>This result shows that the marginal effect of a one-unit change in <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span> is not constant; it depends on the current level of <span class="math inline">\(x\)</span>. For each value of <span class="math inline">\(x\)</span>, the slope of the relationship is different.</li>
</ul>
<p><strong>(b) The Level-Log Model:</strong> For <span class="math inline">\(y = \beta_0 + \beta_1 \log(x) + u\)</span>, show that a 1% change in <span class="math inline">\(x\)</span> leads to an approximate change of <span class="math inline">\((\beta_1/100)\)</span> units in <span class="math inline">\(y\)</span>.</p>
<ol type="1">
<li>First, find the derivative of <span class="math inline">\(y\)</span> with respect to <span class="math inline">\(x\)</span>: <span class="math display">\[ \frac{dy}{dx} = \beta_1 \frac{1}{x} \]</span></li>
<li>Rearrange the equation to find an expression for an infinitesimal change in <span class="math inline">\(y\)</span>, <span class="math inline">\(dy\)</span>: <span class="math display">\[ dy = \beta_1 \frac{dx}{x} \]</span></li>
<li>The term <span class="math inline">\(\frac{dx}{x}\)</span> represents the proportional or percentage change in <span class="math inline">\(x\)</span>. For discrete changes, we can write this as an approximation: <span class="math display">\[ \Delta y \approx \beta_1 \frac{\Delta x}{x} \]</span></li>
<li>If we consider a 1% change in <span class="math inline">\(x\)</span>, then <span class="math inline">\(\frac{\Delta x}{x} = 0.01\)</span>.</li>
<li>Substitute this value into the approximation: <span class="math display">\[ \Delta y \approx \beta_1 (0.01) = \frac{\beta_1}{100} \]</span></li>
</ol>
<ul>
<li>Thus, a 1% change in <span class="math inline">\(x\)</span> is associated with an approximate change in <span class="math inline">\(y\)</span> of <span class="math inline">\((\beta_1/100)\)</span> units.</li>
</ul>
</section>
<section id="perfect-multicollinearity" class="level3">
<h3 class="anchored" data-anchor-id="perfect-multicollinearity">Perfect Multicollinearity</h3>
<p><strong>(a) What does it mean for <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> to have <em>perfect multicollinearity</em>?</strong></p>
<ul>
<li>Perfect multicollinearity means that one explanatory variable is a perfect linear function of another. For example, <span class="math inline">\(x_1 = c_0 + c_1 x_2\)</span> for some constants <span class="math inline">\(c_0\)</span> and <span class="math inline">\(c_1\)</span> where <span class="math inline">\(c_1 \neq 0\)</span>. This means there is no independent variation in <span class="math inline">\(x_1\)</span> that is not associated with <span class="math inline">\(x_2\)</span>. A common example is including a variable in different units (e.g., height in meters and height in centimeters) in the same regression.</li>
</ul>
<p><strong>(b) Analytically, what happens to the value of <span class="math inline">\(R_1^2\)</span> under perfect multicollinearity?</strong></p>
<ul>
<li><span class="math inline">\(R_1^2\)</span> is the R-squared from a regression of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(x_2\)</span>. If <span class="math inline">\(x_1\)</span> is a perfect linear function of <span class="math inline">\(x_2\)</span>, then the regression of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(x_2\)</span> will explain 100% of the variation in <span class="math inline">\(x_1\)</span>. Therefore, <strong><span class="math inline">\(R_1^2 = 1\)</span></strong>.</li>
</ul>
<p><strong>(c) Explain mathematically why it is impossible to calculate <span class="math inline">\(\hat{\beta}_1\)</span>.</strong></p>
<ul>
<li>The variance of the OLS estimator <span class="math inline">\(\hat{\beta}_1\)</span> is given by: <span class="math display">\[ Var(\hat{\beta}_1) = \frac{\sigma^2}{SST_1 (1 - R_1^2)} \]</span></li>
<li>Under perfect multicollinearity, we established that <span class="math inline">\(R_1^2 = 1\)</span>. Substituting this into the denominator: <span class="math display">\[ \text{Denominator} = SST_1 (1 - 1) = SST_1 \cdot 0 = 0 \]</span></li>
<li>The variance of the estimator becomes: <span class="math display">\[ Var(\hat{\beta}_1) = \frac{\sigma^2}{0} \rightarrow \infty \]</span></li>
<li>Since the variance of the estimator is infinite, the OLS estimator is undefined. The OLS procedure fails because it is mathematically impossible to distinguish the unique effect of <span class="math inline">\(x_1\)</span> from the effect of <span class="math inline">\(x_2\)</span> when they are perfectly linearly related.</li>
</ul>
</section>
<section id="zero-conditional-mean" class="level3">
<h3 class="anchored" data-anchor-id="zero-conditional-mean">Zero Conditional Mean</h3>
<p><strong>(a) Explain in your own words what this assumption means.</strong></p>
<ul>
<li>The Zero Conditional Mean assumption, <span class="math inline">\(E(u|x) = 0\)</span>, means that the average value of all unobserved factors (the error term, <span class="math inline">\(u\)</span>) is zero for any given value of the explanatory variable (<span class="math inline">\(x\)</span>). Put simply, it means that the unobserved factors are not systematically related to, or correlated with, the explanatory variable.</li>
</ul>
<p><strong>(b) Using <code>wage</code> on <code>education</code>, explain why “innate ability” violates this assumption.</strong></p>
<ul>
<li>In a model <span class="math inline">\(\text{wage} = \beta_0 + \beta_1 \text{education} + u\)</span>, “innate ability” is an unobserved factor and is therefore part of the error term <span class="math inline">\(u\)</span>.</li>
<li>It is very likely that innate ability is correlated with both <code>wage</code> and <code>education</code>.
<ol type="1">
<li>People with higher ability may earn higher wages regardless of their education level.</li>
<li>People with higher ability may find it easier to succeed in school and are therefore more likely to attain higher levels of education.</li>
</ol></li>
<li>Because <code>ability</code> is in <code>u</code> and is also correlated with <code>education</code>, the average level of <code>u</code> is not zero across different levels of <code>education</code>. Specifically, <span class="math inline">\(E(u|\text{education})\)</span> will be higher for higher levels of <code>education</code>. This violates the Zero Conditional Mean assumption.</li>
</ul>
<p><strong>(c) In which direction will <span class="math inline">\(\hat{\beta}_1\)</span> be biased?</strong></p>
<ul>
<li>The bias will be <strong>positive</strong>. The OLS estimate <span class="math inline">\(\hat{\beta}_1\)</span> will be <strong>overstated</strong>.</li>
<li><strong>Reasoning (using the OVB formula):</strong> The bias is <span class="math inline">\(\beta_2 \cdot \delta_1\)</span>.
<ul>
<li><span class="math inline">\(\beta_2\)</span> is the effect of the omitted variable (ability) on the outcome (wage). This effect is positive (<span class="math inline">\(\beta_2 &gt; 0\)</span>).</li>
<li><span class="math inline">\(\delta_1\)</span> is the correlation between the included variable (education) and the omitted variable (ability). This correlation is also positive (<span class="math inline">\(\delta_1 &gt; 0\)</span>).</li>
</ul></li>
<li>Since the bias term is the product of two positive numbers, the bias is positive. The OLS estimate <span class="math inline">\(\hat{\beta}_1\)</span> will mistakenly attribute some of the wage-increasing effect of ability to education, leading to an estimate that is larger than the true causal effect of education on wages.</li>
</ul>
</section>
<section id="variance-of-the-ols-estimator" class="level3">
<h3 class="anchored" data-anchor-id="variance-of-the-ols-estimator">Variance of the OLS Estimator</h3>
<p><strong>What two things could you do to increase the <em>precision</em> of your estimate, <span class="math inline">\(\hat{\beta}_1\)</span>?</strong></p>
<p>The variance formula is <span class="math inline">\(Var(\hat{\beta}_1) = \frac{\sigma^2}{SST_x}\)</span>. To increase precision, we need to <em>decrease</em> this variance.</p>
<ol type="1">
<li><p><strong>Decrease the error variance (<span class="math inline">\(\sigma^2\)</span>)</strong>: <span class="math inline">\(\sigma^2\)</span> is the variance of the unobserved factors, <span class="math inline">\(u\)</span>. In an experimental setting, this means <strong>making the experimental conditions as controlled and uniform as possible</strong>. For example, ensure all crop plots have the same soil type, water access, and sunlight exposure. By minimizing the influence of other factors, you reduce the “noise” in the model, making the relationship between fertilizer and yield clearer.</p></li>
<li><p><strong>Increase the Total Sum of Squares of x (<span class="math inline">\(SST_x\)</span>)</strong>: <span class="math inline">\(SST_x = \sum(x_i - \bar{x})^2\)</span>. This term measures the total variation in the explanatory variable. In your experiment, this means you should <strong>use a wider range of fertilizer amounts (<span class="math inline">\(x\)</span>) across your different plots</strong>. Intuitively, it is easier to detect a trend line if the points are spread far apart horizontally than if they are all bunched together. More variation in <span class="math inline">\(x\)</span> provides more information to pin down the slope of the regression line.</p></li>
</ol>
</section>
<section id="r-squared" class="level3">
<h3 class="anchored" data-anchor-id="r-squared">R-squared</h3>
<p><strong>Why is a high R-squared not necessarily the ultimate goal? What is often more important?</strong></p>
<ul>
<li>A high R-squared is not the ultimate goal because it only measures <strong>goodness-of-fit</strong>, not <strong>causal validity</strong>. A model can have a very high R-squared but still suffer from severe omitted variable bias, making its coefficients unreliable for policy decisions. For example, a model predicting crime rates using ice cream sales might have a high R-squared in the summer, but the relationship is spurious.</li>
<li>What is often more important is obtaining an <strong>unbiased and consistent estimate of a specific coefficient</strong> that represents a causal effect of interest. For policy, we need to know the true causal impact of changing a variable (e.g., years of education, police funding, carbon tax). This requires a model specification that is theoretically sound and minimizes biases (like OVB), even if it results in a lower R-squared. <strong>Unbiasedness is usually more important than fit.</strong></li>
</ul>
</section>
<section id="omitted-variable-bias-1" class="level3">
<h3 class="anchored" data-anchor-id="omitted-variable-bias-1">Omitted Variable Bias</h3>
<p><strong>What are two or three other variables you would want to include in the <code>wage</code> on <code>education</code> model? What are the practical challenges?</strong></p>
<ul>
<li><strong>Variables to Include:</strong>
<ol type="1">
<li><strong>Cognitive Ability / IQ:</strong> To control for the “innate ability” bias discussed earlier.</li>
<li><strong>Quality of Institution:</strong> The return to a degree from a top university is likely higher than from a less selective one. This could be measured by university ranking or average test scores of admitted students.</li>
<li><strong>Parental Background:</strong> Variables like parents’ education and income can capture family network effects, financial support, and environmental factors that influence both a child’s education and future earnings.</li>
</ol></li>
<li><strong>Practical Challenges:</strong>
<ul>
<li><strong>Data Availability:</strong> Most standard economic datasets (like labor force surveys) do not collect information on IQ, school quality, or detailed parental background.</li>
<li><strong>Measurement:</strong> These variables are difficult to measure accurately. “Ability” is a complex construct, and IQ tests are controversial. “School quality” is also multifaceted and hard to summarize with a single number.</li>
<li><strong>Privacy:</strong> Data on IQ and parental income are highly sensitive and can be difficult to obtain due to privacy concerns.</li>
</ul></li>
</ul>
</section>
<section id="ols-minimization" class="level3">
<h3 class="anchored" data-anchor-id="ols-minimization">OLS Minimization</h3>
<p><strong>Why do we use the <em>sum of squared residuals</em>? Why not absolute values or just the sum?</strong></p>
<ul>
<li><p><strong>Why not the sum of residuals?</strong> Minimizing <span class="math inline">\(\sum e_i\)</span> is not a useful criterion. An infinite number of lines can make this sum equal to zero (any line passing through the point of means, <span class="math inline">\((\bar{x}, \bar{y})\)</span>), so it does not yield a unique solution.</p></li>
<li><p><strong>Why we use the sum of <em>squared</em> residuals:</strong></p>
<ol type="1">
<li><strong>Treats Positive/Negative Errors Equally:</strong> Squaring makes all errors positive, so large positive errors and large negative errors are treated as equally “bad”.</li>
<li><strong>Penalizes Large Errors More:</strong> Squaring gives much more weight to large errors than to small ones (e.g., an error of 2 becomes 4, but an error of 10 becomes 100). This is often desirable, as it forces the line to fit the bulk of the data well by avoiding large deviations.</li>
<li><strong>Mathematical Convenience:</strong> The sum of squares is a smooth, differentiable function. Using calculus, we can easily derive a unique, closed-form analytical solution for the estimators <span class="math inline">\(\hat{\beta}_0\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span>. Minimizing the sum of absolute values (Least Absolute Deviations, or LAD) is computationally more complex and may not have a unique solution.</li>
</ol></li>
</ul>
</section>
<section id="polynomials" class="level3">
<h3 class="anchored" data-anchor-id="polynomials">Polynomials</h3>
<p><strong>When might you suspect a quadratic model would be more appropriate? What would a negative coefficient on the <code>experience²</code> term imply?</strong></p>
<ul>
<li><strong>When to Suspect Non-linearity:</strong>
<ol type="1">
<li><strong>Economic Theory:</strong> Theory might suggest a non-linear relationship. For example, the “law of diminishing marginal returns” is common in economics. The effect of experience on wages is likely positive but decreases as one gets more experienced.</li>
<li><strong>Visual Inspection:</strong> A scatterplot of the dependent variable against the independent variable might reveal a curved, parabolic shape rather than a straight line.</li>
<li><strong>Residual Plots:</strong> If you fit a linear model and then plot the residuals against the independent variable, a U-shaped or inverted U-shaped pattern in the residuals suggests that a quadratic term might be missing.</li>
</ol></li>
<li><strong>Interpretation of a negative <code>experience²</code> coefficient:</strong>
<ul>
<li>In the model <span class="math inline">\(\text{wage} = \beta_0 + \beta_1 \text{experience} + \beta_2 \text{experience}^2 + u\)</span>, if <span class="math inline">\(\beta_1 &gt; 0\)</span> and <span class="math inline">\(\beta_2 &lt; 0\)</span>, it implies a <strong>concave, inverted U-shaped relationship</strong> between experience and wage.</li>
<li>This means that as a person gains their first few years of experience, their wage increases (<span class="math inline">\(\beta_1\)</span> term dominates). However, the rate of this increase slows down over time (the negative <span class="math inline">\(\beta_2\)</span> term starts to have more impact). This reflects <strong>diminishing marginal returns to experience</strong>. Eventually, after a certain point, an additional year of experience might even lead to a decrease in predicted wages (if the person becomes less adaptable or their skills become obsolete).</li>
</ul></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>